# DAY 1

## RAG System Flow Process

### Memory System
- Smash-based board systems.
- Asking vague or irrelevant questions lowers the system’s value.
- Poor decisions can be expensive.
- Need to scale up despite limited hardware resources.

### Always-On Mode
- Optimized solutions lead to better results.
- **Recommendation Systems** are widely used.
- Heavy dependence on specific hardware increases costs.

> RAM is the most widely used structure in AI architectures.

- Avoid using rigid, hardcoded systems.
- Vector-based approaches dominate AI implementation.
- Well-designed systems are easier to implement and maintain.
- **RAG (Retrieval-Augmented Generation)** systems reflect stored knowledge when queried.
- Output can be in the form of text, audio, or other formats.

## Reinforcement Learning (RL)
- May involve end-to-end models or fine-tuned systems.
- The ML platform matters significantly when deploying models.

---

## Performance Optimization

- Some systems use **Guardian Nodes** for deployment.
- **Cache** plays a vital role in improving performance (see cache schematic).
- About **30% of systems** are secured for safety.
- Roughly **10% are duplicated** due to schema-based calculations.
- All these help in **reducing computational power consumption**.

### Enterprise-Scale RAG Systems
- Provide major benefits through **context-aware** answers.
- Web-based RAG systems often have limited compute resources.
- Contextual understanding leads to better responses and user experience.
- Ethical practices must be considered during deployment.

> Enterprise RAG systems offer **context-rich and reliable** answers.

---

## Dashboards & Visualization

- AI can now generate **detailed dashboards** effectively.
- Became more practical after industrial-level AI development.

---

##  Reasoning Machines

- We still don’t fully understand how AI reasoning works.
- Some breakthroughs are from **DeepMind researchers**.
- The journey began with **Chain of Thought reasoning**.

---

## Attention Mechanism

- Essential for creating intelligent AI agents.
- Became popular with the arrival of **Transformer architecture**.
- Helps systems focus on relevant input and context.
- The more it can attend to, the more accurately it performs.

> Attention allows AI to tackle complex tasks when multiple agents are involved.

- Introduced in the 2017 paper **“Attention Is All You Need”**.
- The model’s efficiency depends heavily on attention strength and data quality.

---

## Sequence Modeling

- Sentence meaning depends heavily on **context**.
- AI uses **Sequence-to-Sequence (Seq2Seq)** models for better understanding.
- Recommender systems now utilize **Contrastive Loss** functions.
- These are foundational for today’s **RAG-based architectures**.



